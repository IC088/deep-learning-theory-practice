{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "torch.cuda.manual_seed_all(17)\n",
    "random.seed(17)\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "valid_chars = string.ascii_letters + string.digits + \"\"\" .,:;\"'()[]!?+=/\"\"\"\n",
    "num_chars = len(valid_chars) + 2\n",
    "\n",
    "class Corpus(Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.mapping = self._get_mapping()\n",
    "        self.text = self._load_text()\n",
    "        \n",
    "    def sentence_to_tensor(self, sentence):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape (chars, onehot)\n",
    "        \"\"\"\n",
    "        sentence_tensor = torch.Tensor(len(sentence), len(self.mapping))\n",
    "        for position in range(len(sentence)):\n",
    "            character = sentence[position]\n",
    "            sentence_tensor[position] = self.one_hot(character)\n",
    "        return sentence_tensor\n",
    "    \n",
    "    def get_label_from_tensor(self, sequence):\n",
    "        \"\"\"\n",
    "        Returns a tensor shifted by one to the left,\n",
    "        with an EOS ('|') tag at the end.\n",
    "        \"\"\"\n",
    "        label_tensor = torch.Tensor(len(sequence))\n",
    "        for position in range(len(sequence) - 1):\n",
    "            character = torch.argmax(sequence[position + 1])\n",
    "            label_tensor[position] = character\n",
    "        label_tensor[-1] = self.mapping['|']\n",
    "        return label_tensor\n",
    "    \n",
    "    def _load_text(self):\n",
    "        with open(self.file) as f:\n",
    "            return f.read().strip().split('\\n')\n",
    "        \n",
    "    def _get_mapping(self):\n",
    "        mapping = {}\n",
    "        mapping['*'] = 0\n",
    "        for idx in range(1, len(valid_chars) + 1):\n",
    "            mapping[valid_chars[idx - 1]] = idx\n",
    "        mapping['|'] = len(valid_chars) + 1\n",
    "        return mapping\n",
    "    \n",
    "    def one_hot(self, character):\n",
    "        \"\"\"\n",
    "        Transforms a single character toa one-hot tensor.\n",
    "        \"\"\"\n",
    "        one_hot = torch.zeros(len(self.mapping))\n",
    "        index = torch.Tensor([self.mapping[character]])\n",
    "        one_hot = one_hot.scatter(0, index.long(), 1)\n",
    "        return one_hot\n",
    "    \n",
    "    def split(self, train_ratio, val_ratio, test_ratio):\n",
    "        if (train_ratio + val_ratio + test_ratio != 1.0):\n",
    "            raise Exception(\"Ratios should sum to one.\")\n",
    "        dataset_length = len(self)\n",
    "        train_length = int(train_ratio * dataset_length)\n",
    "        val_length = int(val_ratio * dataset_length)\n",
    "        test_length = len(self) - train_length - val_length\n",
    "        splits = [train_length, val_length, test_length]\n",
    "        return random_split(self, splits)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            sequence: tensor of shape (chars, onehot)\n",
    "            length: int length of sequence\n",
    "            label: shifted tensor of shape (chars, onehot)\n",
    "        \"\"\"\n",
    "        sequence = self.sentence_to_tensor(self.text[idx])\n",
    "        length = len(sequence)\n",
    "        label = self.get_label_from_tensor(sequence)\n",
    "        return sequence, length, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "class SpockNet(nn.Module):\n",
    "    def __init__(self, num_chars, hidden_size, num_layers, dropout=0.5):\n",
    "        super(SpockNet, self).__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(num_chars, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_chars)\n",
    "        \n",
    "    def forward(self, sentence, lengths, hc):\n",
    "        batch_size, sequence_length = sentence.size()[:-1]\n",
    "        sentence = pack_padded_sequence(sentence, lengths, batch_first=True)\n",
    "        lstm_out, hc = self.lstm(sentence, hc)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True, padding_value=0)\n",
    "        lstm_out = lstm_out.contiguous()\n",
    "        lstm_out = lstm_out.view(-1, lstm_out.shape[2])\n",
    "        output = self.fc(lstm_out)\n",
    "        output = output.view(batch_size, sequence_length, self.num_chars)\n",
    "        return output, hc\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(device),\n",
    "            weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, batch):\n",
    "        # batch: list of N tuples of (data (tensor), length (int), label (tensor))\n",
    "        batch.sort(reverse=True, key=lambda x: x[1])\n",
    "        data, _, label = zip(*batch)\n",
    "        self.lengths = torch.Tensor([len(d) for d in data])\n",
    "        self.data = pad_sequence(data, batch_first=True)\n",
    "        self.label = pad_sequence(label, batch_first=True)\n",
    "        \n",
    "def batch_function(batch):\n",
    "    return Batch(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i.stack.imgur.com/SjnTl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "\n",
    "corpus = Corpus('clean.txt')\n",
    "train, val, test = corpus.split(0.8, 0.2, 0)\n",
    "\n",
    "mapping = list(corpus.mapping.keys())\n",
    "\n",
    "batch_size = 32\n",
    "model = SpockNet(num_chars, 200, 2, dropout=0.1).to(device)\n",
    "train_loader = DataLoader(train, collate_fn=batch_function, batch_size=batch_size, num_workers=8)\n",
    "val_loader = DataLoader(val, collate_fn=batch_function, batch_size=batch_size, num_workers=8)\n",
    "\n",
    "start_letters = 'ABCDEFGHIJKLMNOPRSTUVWZ'\n",
    "max_sampling_length = 500\n",
    "temperature = 0.5\n",
    "\n",
    "def get_sample(model, hc):\n",
    "    model.eval()\n",
    "    mapping = list(corpus.mapping.keys())\n",
    "    letter = random.choice(start_letters)\n",
    "    prediction = letter\n",
    "    letter_tensor = corpus.one_hot(letter).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        hc = model.init_hidden(1)\n",
    "        while (letter != '|') and (len(prediction) < max_sampling_length):\n",
    "            output, hc = model(letter_tensor, torch.tensor([1]), hc)\n",
    "            distribution = torch.softmax(torch.div(torch.flatten(output), temperature), dim=0)\n",
    "            distribution = torch.distributions.multinomial.Multinomial(1, distribution)\n",
    "            sample = distribution.sample()\n",
    "            letter = mapping[torch.argmax(sample)]\n",
    "            if letter != '|':\n",
    "                prediction += letter\n",
    "            letter_tensor = corpus.one_hot(letter).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    return prediction\n",
    "\n",
    "def run_train(epoch):\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    true_positive = 0\n",
    "    sample_count = 0\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        model.train()\n",
    "        start = time()\n",
    "        optimizer.zero_grad()\n",
    "        input = batch.data.to(device)\n",
    "        target = batch.label.to(device)\n",
    "        lengths = batch.lengths.to(device)\n",
    "        hc = model.init_hidden(len(input))\n",
    "        output, _ = model(input, lengths, hc)\n",
    "        output = output.to(device)\n",
    "        output = output.view(-1, num_chars)\n",
    "        target = target.view(-1)\n",
    "        loss = criterion(output, target.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        sample_count += len(output)\n",
    "        true_positive += torch.sum(pred == target.long())\n",
    "        train_acc = (true_positive.float() / sample_count)\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(train_acc)\n",
    "        if idx % 200 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Epoch {} | Training batch {}/{} ({}%)\".format(epoch, idx + 1, len(train_loader),\n",
    "                    int((idx + 1) / len(train_loader) * 100)))\n",
    "            print(\"Training loss: {} | Training accuracy: {} | Time per batch: {}\".format(loss.item(),\n",
    "                    train_acc, time() - start))\n",
    "            prediction = get_sample(model, epoch)\n",
    "            print(prediction)\n",
    "\n",
    "    with open('temperature_sample_epoch_{}'.format(epoch), 'a') as file:\n",
    "        for i in range(20):\n",
    "            prediction = get_sample(model, epoch)\n",
    "            file.write(prediction)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def run_validate(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        true_positive = 0\n",
    "        sample_count = 0\n",
    "        start = time()\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            input = batch.data.to(device)\n",
    "            target = batch.label.to(device)\n",
    "            lengths = batch.lengths.to(device)\n",
    "            hc = model.init_hidden(len(input))\n",
    "            output, _ = model(input, lengths, hc)\n",
    "            output = output.to(device)\n",
    "            output = output.view(-1, num_chars)\n",
    "            target = target.view(-1)\n",
    "            loss = criterion(output, target.long())\n",
    "            val_loss += loss\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            sample_count += len(output)\n",
    "            true_positive += torch.sum(pred == target.long())\n",
    "            clear_output(wait=True)\n",
    "            print(\"Epoch {} | Validating batch {}/{} ({}%)\".format(epoch, idx + 1, len(val_loader),\n",
    "                                                        int((idx + 1) / len(val_loader) * 100)))\n",
    "        clear_output(wait=True)\n",
    "        print(\"Epoch {} | Validating batch {}/{} ({}%)\".format(epoch, idx + 1, len(val_loader),\n",
    "                                                    int((idx + 1) / len(val_loader) * 100)))\n",
    "        val_acc = (true_positive.float() / sample_count)\n",
    "        val_loss /= len(val_loader)\n",
    "        print(\"Validation loss: {} | Validation accuracy: {} | Time for validation: {}\".format(val_loss.item(),\n",
    "                val_acc, time() - start))\n",
    "    return val_loss.item(), val_acc\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "\n",
    "num_epochs = 30\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "experiment = '2'\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    scheduler.step()\n",
    "    train_loss, train_acc = run_train(epoch)\n",
    "    val_loss, val_acc = run_validate(epoch)\n",
    "    training_losses.append(torch.mean(torch.Tensor(train_loss)))\n",
    "    training_accuracies.append(train_acc)\n",
    "    validation_losses.append(val_loss)\n",
    "    validation_accuracies.append(val_acc)\n",
    "    \n",
    "    torch.save(model.state_dict(), 'experiment-{}/model_{}.pt'.format(experiment))\n",
    "    with open('epoch_{}.txt'.format(experiment), 'a') as f:\n",
    "        f.write(str(epoch) + ' ')\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    ta = np.array([x.item() for x in training_accuracies]) *100\n",
    "    va = np.array([x.item() for x in validation_accuracies]) *100\n",
    "    fig, ax = plt.subplots(figsize=(16,9))\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.plot(training_losses, '--', linewidth=4, label=\"Training loss\")\n",
    "    ax.plot(validation_losses, 'r--', linewidth=4, label=\"Validation loss\")\n",
    "    ax2.plot(ta, linewidth=4, label=\"Training acc\")\n",
    "    ax2.plot(va, 'r', linewidth=4, label=\"Validation acc\")\n",
    "    ax.legend(loc='center', bbox_to_anchor=(0.8, 0.3))\n",
    "    ax2.legend(loc='center', bbox_to_anchor=(0.8, 0.8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
